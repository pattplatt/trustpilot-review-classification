{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickmuller/miniconda3/envs/torch_vae/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['URL', 'Category', 'Title', 'Review', 'Rating', 'Language',\n",
      "       'Review Number', 'Page Number', 'Review_Length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.read_csv(\"./data/full_dataset.csv\",delimiter=\",\",encoding=\"utf8\")\n",
    "\n",
    "print(full_df.columns)\n",
    "#Create a new dataset containing only reviews with Language 'de'\n",
    "df_de = full_df[full_df['Language'] == 'de']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating\n",
      "5    207177\n",
      "1     80995\n",
      "4     27809\n",
      "3      8352\n",
      "2      7918\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_de['Rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN or empty strings\n",
    "df_de = df_de.dropna(subset=['Review'])\n",
    "df_de = df_de[df_de['Review'].str.strip() != '']\n",
    "df_de = df_de[df_de['Review'].str.split().str.len() >= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove reviews that have little info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_info_phrases = [\n",
    "    'gut', 'sehr gut', 'ok', 'super', 'toll', 'klasse', 'nicht schlecht', \n",
    "    'passt', 'in ordnung', 'zufrieden', 'alles gut', 'empfehlenswert', \n",
    "    'schnell', 'top', 'prima', 'geht so', 'naja', 'schlecht', 'geht', \n",
    "    'super service', 'alles bestens', 'hat gepasst'\n",
    "]\n",
    "\n",
    "# Lowercase and strip each review\n",
    "df_de['Review_clean'] = df_de['Review'].str.lower().str.strip()\n",
    "\n",
    "# Remove reviews that exactly match low-info phrases\n",
    "df_de = df_de[~df_de['Review_clean'].isin(low_info_phrases)]\n",
    "\n",
    "# Optional: Remove reviews that only contain one of the phrases\n",
    "df_de = df_de[~df_de['Review_clean'].apply(lambda x: any(p in x for p in low_info_phrases) and len(x.split()) <= 3)]\n",
    "\n",
    "# Drop the helper column if needed\n",
    "df_de = df_de.drop(columns=['Review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating\n",
      "5    191381\n",
      "1     80435\n",
      "4     26248\n",
      "3      8251\n",
      "2      7875\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_de['Rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating\n",
      "1    50000\n",
      "5    50000\n",
      "4    26248\n",
      "3     8251\n",
      "2     7875\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate the classes\n",
    "df_rating_5 = df_de[df_de['Rating'] == 5]\n",
    "df_rating_4 = df_de[df_de['Rating'] == 4]\n",
    "df_rating_3 = df_de[df_de['Rating'] == 3]\n",
    "df_rating_2 = df_de[df_de['Rating'] == 2]\n",
    "df_rating_1 = df_de[df_de['Rating'] == 1]\n",
    "\n",
    "# Undersample labels 5 and 1 to 50,000\n",
    "df_rating_5 = df_rating_5.sample(n=50000, random_state=42)\n",
    "df_rating_1 = df_rating_1.sample(n=50000, random_state=42)\n",
    "\n",
    "# Combine all into a new balanced DataFrame\n",
    "df_downsampled_inbalanced = pd.concat([df_rating_5, df_rating_4, df_rating_3, df_rating_2, df_rating_1])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_downsampled_inbalanced = df_downsampled_inbalanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(df_downsampled_inbalanced['Rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add augmented data to main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  Rating\n",
      "0  Alles wird auch die Post teurer... aber das Mo...       3\n",
      "1  ['Alles wird teurer auch der Beitrag...aber di...       3\n",
      "2  Hier weiß die linke Hand nicht, was die rechte...       2\n",
      "3  ['Hier weiß die linke Hand nicht, was die rech...       2\n",
      "4  Sehr umständlich, wenn man als Lehrling eine S...       3\n"
     ]
    }
   ],
   "source": [
    "augmented_df = pd.read_csv('./data/augmented_reviews.csv',delimiter=\",\", encoding=\"utf8\")\n",
    "print(augmented_df.head())\n",
    "\n",
    "# Identify the missing columns in augmented_df.\n",
    "missing_cols = set(df_downsampled_inbalanced.columns) - set(augmented_df.columns)\n",
    "\n",
    "# Add the missing columns to augmented_df, filling them with NaN.\n",
    "for col in missing_cols:\n",
    "    augmented_df[col] = np.nan  # or use an appropriate default value\n",
    "\n",
    "# Reorder augmented_df to match the column order of df_de.\n",
    "augmented_df = augmented_df[df_downsampled_inbalanced.columns]\n",
    "\n",
    "# Concatenate the two DataFrames.\n",
    "df_downsampled_inbalanced_augmented = pd.concat([df_downsampled_inbalanced, augmented_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating\n",
      "1    50000\n",
      "5    50000\n",
      "4    26248\n",
      "3    24753\n",
      "2    23625\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_downsampled_inbalanced_augmented['Rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (139700, 9)\n",
      "Validation shape: (17463, 9)\n",
      "Test shape: (17463, 9)\n",
      "Train rating distribution:\n",
      "Rating\n",
      "1    0.286328\n",
      "5    0.286328\n",
      "4    0.150308\n",
      "3    0.141747\n",
      "2    0.135290\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation rating distribution:\n",
      "Rating\n",
      "1    0.286320\n",
      "5    0.286320\n",
      "4    0.150318\n",
      "3    0.141785\n",
      "2    0.135257\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test rating distribution:\n",
      "Rating\n",
      "1    0.286320\n",
      "5    0.286320\n",
      "4    0.150318\n",
      "3    0.141728\n",
      "2    0.135315\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split into train (80%) and temp (20%)\n",
    "df_train, df_temp = train_test_split(\n",
    "    df_downsampled_inbalanced_augmented,\n",
    "    test_size=0.2,\n",
    "    stratify=df_downsampled_inbalanced_augmented['Rating'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split temp into validation (10%) and test (10%)\n",
    "df_val, df_test = train_test_split(\n",
    "    df_temp,\n",
    "    test_size=0.5,\n",
    "    stratify=df_temp['Rating'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Validation shape: {df_val.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")\n",
    "\n",
    "# Optional: Check rating distributions\n",
    "print(\"Train rating distribution:\")\n",
    "print(df_train['Rating'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nValidation rating distribution:\")\n",
    "print(df_val['Rating'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest rating distribution:\")\n",
    "print(df_test['Rating'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train_inbalanced.csv\", index=False)\n",
    "df_val.to_csv(\"val_inbalanced.csv\", index=False)\n",
    "df_test.to_csv(\"test_inbalanced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using a German BERT\n",
    "model_name = \"dbmdz/bert-base-german-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded = tokenizer(\n",
    "    df_train['Review'].tolist(),       # a list of strings (the reviews)\n",
    "    padding=True,          # pad to longest in batch\n",
    "    truncation=True,       # truncate if it’s longer than the model’s max length\n",
    "    return_tensors=\"pt\"    # return PyTorch tensors\n",
    ")\n",
    "\n",
    "df_val_encoded = tokenizer(\n",
    "    df_val['Review'].tolist(),       # a list of strings (the reviews)\n",
    "    padding=True,          # pad to longest in batch\n",
    "    truncation=True,       # truncate if it’s longer than the model’s max length\n",
    "    return_tensors=\"pt\"    # return PyTorch tensors\n",
    ")\n",
    "\n",
    "df_test_encoded = tokenizer(\n",
    "    df_test['Review'].tolist(),       # a list of strings (the reviews)\n",
    "    padding=True,          # pad to longest in batch\n",
    "    truncation=True,       # truncate if it’s longer than the model’s max length\n",
    "    return_tensors=\"pt\"    # return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(df_train_encoded, \"train_inbalanced_tokenized.pt\")\n",
    "torch.save(df_val_encoded, \"val_inbalanced_tokenized.pt\")\n",
    "torch.save(df_test_encoded, \"test_inbalanced_tokenized.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating\n",
      "1    23625\n",
      "2    23625\n",
      "5    23625\n",
      "4    23625\n",
      "3    23625\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate the classes\n",
    "df_rating_5 = df_downsampled_inbalanced_augmented[df_downsampled_inbalanced_augmented['Rating'] == 5]\n",
    "df_rating_4 = df_downsampled_inbalanced_augmented[df_downsampled_inbalanced_augmented['Rating'] == 4]\n",
    "df_rating_3 = df_downsampled_inbalanced_augmented[df_downsampled_inbalanced_augmented['Rating'] == 3]\n",
    "df_rating_2 = df_downsampled_inbalanced_augmented[df_downsampled_inbalanced_augmented['Rating'] == 2]\n",
    "df_rating_1 = df_downsampled_inbalanced_augmented[df_downsampled_inbalanced_augmented['Rating'] == 1]\n",
    "\n",
    "# Undersample labels 5 and 1 to 50,000\n",
    "df_rating_5 = df_rating_5.sample(n=23625, random_state=42)\n",
    "df_rating_4 = df_rating_4.sample(n=23625, random_state=42)\n",
    "df_rating_3 = df_rating_3.sample(n=23625, random_state=42)\n",
    "df_rating_1 = df_rating_1.sample(n=23625, random_state=42)\n",
    "\n",
    "# Combine all into a new balanced DataFrame\n",
    "df_downsampled_balanced_augmented = pd.concat([df_rating_5, df_rating_4, df_rating_3, df_rating_2, df_rating_1])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_downsampled_balanced_augmented = df_downsampled_balanced_augmented.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(df_downsampled_balanced_augmented['Rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (94500, 9)\n",
      "Validation shape: (11812, 9)\n",
      "Test shape: (11813, 9)\n",
      "Train rating distribution:\n",
      "Rating\n",
      "2    0.2\n",
      "4    0.2\n",
      "3    0.2\n",
      "1    0.2\n",
      "5    0.2\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation rating distribution:\n",
      "Rating\n",
      "5    0.200051\n",
      "2    0.200051\n",
      "1    0.199966\n",
      "4    0.199966\n",
      "3    0.199966\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test rating distribution:\n",
      "Rating\n",
      "3    0.200034\n",
      "4    0.200034\n",
      "1    0.200034\n",
      "2    0.199949\n",
      "5    0.199949\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split into train (80%) and temp (20%)\n",
    "df_train, df_temp = train_test_split(\n",
    "    df_downsampled_balanced_augmented,\n",
    "    test_size=0.2,\n",
    "    stratify=df_downsampled_balanced_augmented['Rating'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split temp into validation (10%) and test (10%)\n",
    "df_val, df_test = train_test_split(\n",
    "    df_temp,\n",
    "    test_size=0.5,\n",
    "    stratify=df_temp['Rating'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Validation shape: {df_val.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")\n",
    "\n",
    "# Optional: Check rating distributions\n",
    "print(\"Train rating distribution:\")\n",
    "print(df_train['Rating'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nValidation rating distribution:\")\n",
    "print(df_val['Rating'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest rating distribution:\")\n",
    "print(df_test['Rating'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train_balanced_5_classes.csv\", index=False)\n",
    "df_val.to_csv(\"val_balanced_5_classes.csv\", index=False)\n",
    "df_test.to_csv(\"test_balanced_5_classes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded = tokenizer(\n",
    "    df_train['Review'].tolist(),       # a list of strings (the reviews)\n",
    "    padding=True,          # pad to longest in batch\n",
    "    truncation=True,       # truncate if it’s longer than the model’s max length\n",
    "    return_tensors=\"pt\"    # return PyTorch tensors\n",
    ")\n",
    "\n",
    "df_val_encoded = tokenizer(\n",
    "    df_val['Review'].tolist(),       # a list of strings (the reviews)\n",
    "    padding=True,          # pad to longest in batch\n",
    "    truncation=True,       # truncate if it’s longer than the model’s max length\n",
    "    return_tensors=\"pt\"    # return PyTorch tensors\n",
    ")\n",
    "\n",
    "df_test_encoded = tokenizer(\n",
    "    df_test['Review'].tolist(),       # a list of strings (the reviews)\n",
    "    padding=True,          # pad to longest in batch\n",
    "    truncation=True,       # truncate if it’s longer than the model’s max length\n",
    "    return_tensors=\"pt\"    # return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(df_train_encoded, \"train_balanced_tokenized_5_classes.pt\")\n",
    "torch.save(df_val_encoded, \"val_balanced_tokenized_5_classes.pt\")\n",
    "torch.save(df_test_encoded, \"test_balanced_tokenized_5_classes.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
